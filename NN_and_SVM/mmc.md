### â­ **Maximum Margin Classifier**


# ğŸ’¡ **What is Maximum Margin?**

SVM tries to draw a line (or hyperplane) that:

ğŸ‘‰ Separates the classes
ğŸ‘‰ **With the largest possible gap** between them

This gap is called the **margin**.

Larger margin = more confidence = fewer mistakes = better generalization.

---

# ğŸ¯ **Goal of SVM**

Find the hyperplane that offers **maximum margin**.

So instead of ANY separating line, SVM finds the **best** one.

---

# ğŸ§± **1. Hyperplane Equation**

For a hyperplane:


$w^T x + b = 0$


Where:

* **w** = weight vector (controls direction)
* **b** = bias (controls position)

---

# ğŸ§± **2. Distance From Hyperplane**

Distance of any point x from the hyperplane is:


$\frac{|w^T x + b|}{||w||}$


This is crucial.

---

# ğŸ’¥ **3. Definition of Margin**

Margin = distance between **support vectors** and the hyperplane.

Margin formula:


$\text{Margin} = \frac{2}{||w||}$


ğŸ‘‰ So if you want a **larger margin**, you want **smaller weight magnitude**.

---

# â­ **4. Maximum Margin Explained Using Graph**

```
Class +1     â€¢      o Support Vector
              \    /
               \  /
---------------- HYPERPLANE ---------------
               /  \
              /    \
Class -1     o      â€¢ Support Vector
```

Margin = distance from hyperplane to nearest points of each class.

---

# ğŸ”¥ **5. Optimization Problem (Very Important for Exam)**

We want to *maximize margin*:


$\max \frac{2}{||w||}$


Equivalent to:


$\min \frac{1}{2}||w||^2$


Subject to constraints:


$y_i (w^T x_i + b) \ge 1$


Where:

* $(y_i = +1) or (y_i = -1) (class labels)$

This ensures data is correctly classified **AND** lies outside the margin.

This is the **primal form** of SVM.

---

# ğŸŒŸ **6. Why Margin = 2/||w|| ?**

Because:

* The distance between the two parallel hyperplanes is 2/||w||
* These hyperplanes touch the closest points (support vectors)

These two boundaries are:

1. For class +1:
   
   $w^T x_i + b = 1$
   

2. For class â€“1:
   
   $w^T x_i + b = -1$


Distance between these = 2 / ||w||

---

# â­ In short

**Definition:**
â€œMaximum margin classifier is an SVM model that finds the separating hyperplane which maximizes the distance (margin) between the nearest data points of each class, known as support vectors.â€

**Objective:**

$\min \frac{1}{2}||w||^2$

**Subject to constraints:**

$y_i(w^Tx_i + b) \ge 1$


**Reason:**
Maximizing margin improves generalization and reduces overfitting.

---

# ğŸ”¥ INTUITION

* Larger margin = classifier is more confident
* Less sensitive to noise
* Less likely to overfit
* Better performance on unseen data

---
